#!/usr/bin/env python3
"""
æ”¹è¿›çš„å¿«é€ŸRLè®­ç»ƒè„šæœ¬ - æ”¯æŒæ•°æ®åˆ†å‰²å’Œæœªè§æ•°æ®è¯„ä¼°
"""

import argparse
import sys
import json
import time
import os
import numpy as np
from pathlib import Path
from typing import List, Dict, Any

# æ·»åŠ srcåˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent / "src"))

from data_types import PairwiseExample, RLConfig
from attacks import (
    FlipAttackFWO, FlipAttackFCW, FlipAttackFCS, UncertaintyAttack, PositionAttack, DistractorAttack,
    PromptInjectionAttack, MarkerInjectionAttack, FormattingAttack,
    AuthorityAttack, UnicodeAttack, CoTPoisoningAttack, EmojiAttack
)
from evaluation.qwen_judge import create_qwen_judge
from evaluation.llama_judge import create_llama_judge
from rl.enhanced_environment import EnhancedHydraAttackEnv
from rl.agent import DQNAgent
from rl.trainer import RLTrainer, evaluate_on_unseen_data
from utils.logger import HydraLogger


def convert_numpy_types(obj):
    """è½¬æ¢numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹ï¼Œç”¨äºJSONåºåˆ—åŒ–"""
    if isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, dict):
        return {key: convert_numpy_types(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_numpy_types(item) for item in obj]
    else:
        return obj


def load_benchmark_data(benchmark: str, max_samples = 100, random_seed: int = 42, validation_ratio: float = 0.1) -> tuple[List[PairwiseExample], List[PairwiseExample]]:
    """åŠ è½½benchmarkæ•°æ®å¹¶åˆ†å‡ºéªŒè¯é›†ï¼ˆå¿…é¡»ä½¿ç”¨é¢„åˆ†å‰²æ•°æ®ï¼‰"""
    # å¿…é¡»ä½¿ç”¨é¢„åˆ†å‰²çš„è®­ç»ƒæ•°æ®
    train_file = f"data/split/{benchmark}_train.json"
    
    if not os.path.exists(train_file):
        print(f"âŒ é¢„åˆ†å‰²çš„è®­ç»ƒæ•°æ®ä¸å­˜åœ¨: {train_file}")
        print("è¯·å…ˆè¿è¡Œ prepare_data.py è„šæœ¬å‡†å¤‡æ•°æ®åˆ†å‰²")
        raise FileNotFoundError(f"é¢„åˆ†å‰²çš„è®­ç»ƒæ•°æ®ä¸å­˜åœ¨: {train_file}")
    
    # ä½¿ç”¨é¢„åˆ†å‰²çš„è®­ç»ƒæ•°æ®
    with open(train_file, 'r') as f:
        data = json.load(f)
    
    print(f"âœ… ä½¿ç”¨é¢„åˆ†å‰²çš„è®­ç»ƒæ•°æ®: {len(data)} æ ·æœ¬")
    
    # é™åˆ¶æ ·æœ¬æ•°é‡
    if max_samples != "full" and max_samples is not None:
        try:
            max_samples_int = int(max_samples)
            if len(data) > max_samples_int:
                data = data[:max_samples_int]
        except (ValueError, TypeError):
            # å¦‚æœmax_samplesæ— æ³•è½¬æ¢ä¸ºæ•´æ•°ï¼Œå¿½ç•¥é™åˆ¶
            pass
    
    # è½¬æ¢ä¸ºPairwiseExampleå¯¹è±¡
    examples = []
    for sample in data:
        example = PairwiseExample(
            question_id=sample["question_id"],
            instruction=sample["instruction"],
            response_a=sample["response_a"],
            response_b=sample["response_b"],
            model_a=sample["model_a"],
            model_b=sample["model_b"],
            metadata=sample.get("metadata", {})
        )
        examples.append(example)
    
    # ä»è®­ç»ƒé›†ä¸­åˆ†å‡ºéªŒè¯é›†
    if validation_ratio > 0 and len(examples) > 1:
        np.random.seed(random_seed)
        n_total = len(examples)
        n_validation = int(n_total * validation_ratio)
        
        # éšæœºæ‰“ä¹±æ•°æ®
        indices = np.random.permutation(n_total)
        
        # åˆ†å‡ºéªŒè¯é›†å’Œè®­ç»ƒé›†
        validation_indices = indices[:n_validation]
        train_indices = indices[n_validation:]
        
        train_examples = [examples[i] for i in train_indices]
        validation_examples = [examples[i] for i in validation_indices]
        
        print(f"âœ… æ•°æ®åˆ†å‰²: è®­ç»ƒé›† {len(train_examples)} æ ·æœ¬, éªŒè¯é›† {len(validation_examples)} æ ·æœ¬")
        
        return train_examples, validation_examples
    else:
        print(f"âœ… ä½¿ç”¨å…¨éƒ¨æ•°æ®ä½œä¸ºè®­ç»ƒé›†: {len(examples)} æ ·æœ¬")
        return examples, []




def get_attack_methods() -> List[Any]:
    """è·å–æ‰€æœ‰æ”»å‡»æ–¹æ³•å®ä¾‹"""
    attacks = [
        FlipAttackFCS(),
        FlipAttackFWO(),
        FlipAttackFCW(),
        UncertaintyAttack(),
        PositionAttack(),
        DistractorAttack(),
        PromptInjectionAttack(),
        MarkerInjectionAttack(),
        FormattingAttack(),
        AuthorityAttack(),
        UnicodeAttack(),
        CoTPoisoningAttack(),
        EmojiAttack(),
    ]
    return attacks



def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="è®­ç»ƒå¿«é€ŸRLæ”»å‡»æ™ºèƒ½ä½“ï¼ˆæ”¯æŒæ•°æ®åˆ†å‰²ï¼‰")
    parser.add_argument("--benchmark", type=str, default="alpaca_eval", 
                       choices=["alpaca_eval", "arena_hard", "code_judge_bench"],
                       help="ä½¿ç”¨çš„benchmark")
    parser.add_argument("--max_samples", default=100, help="æ€»æ ·æœ¬æ•°ï¼Œä½¿ç”¨ 'full' è¡¨ç¤ºä½¿ç”¨å…¨é‡æ•°æ®")
    parser.add_argument("--train_ratio", type=float, default=0.8, help="è®­ç»ƒé›†æ¯”ä¾‹")
    parser.add_argument("--test_ratio", type=float, default=0.2, help="æµ‹è¯•é›†æ¯”ä¾‹")
    parser.add_argument("--validation_ratio", type=float, default=0.1, help="éªŒè¯é›†æ¯”ä¾‹ï¼ˆä»è®­ç»ƒé›†ä¸­åˆ†å‡ºï¼‰")
    parser.add_argument("--judge_model_path", type=str, required=True, help="Judgeæ¨¡å‹è·¯å¾„")
    parser.add_argument("--judge_type", type=str, default="qwen", help="Judgeç±»å‹")
    parser.add_argument("--episodes", type=int, default=1000, help="è®­ç»ƒè½®æ•°")
    parser.add_argument("--max_queries", type=int, default=10, help="æœ€å¤§æŸ¥è¯¢æ¬¡æ•°")
    parser.add_argument("--learning_rate", type=float, default=0.001, help="å­¦ä¹ ç‡")
    parser.add_argument("--batch_size", type=int, default=32, help="æ‰¹æ¬¡å¤§å°")
    parser.add_argument("--model_dir", type=str, default="./models", help="æ¨¡å‹ä¿å­˜ç›®å½•")
    parser.add_argument("--log_dir", type=str, default="./logs", help="æ—¥å¿—ç›®å½•")
    parser.add_argument("--random_seed", type=int, default=42, help="éšæœºç§å­")
    parser.add_argument("--eval_freq", type=int, default=500, help="éªŒè¯é¢‘ç‡ï¼ˆæ¯å¤šå°‘ä¸ªepisodeè¯„ä¼°ä¸€æ¬¡ï¼‰")
    parser.add_argument("--early_stopping_patience", type=int, default=10, help="Early stopping patience")
    parser.add_argument("--early_stopping_min_delta", type=float, default=0.001, help="Early stoppingæœ€å°æ”¹å–„é˜ˆå€¼")
    
    # DQNç®—æ³•ç‰¹æœ‰å‚æ•°
    parser.add_argument("--hidden_dim", type=int, default=512, help="ç¥ç»ç½‘ç»œéšè—å±‚ç»´åº¦")
    parser.add_argument("--gamma", type=float, default=0.99, help="æŠ˜æ‰£å› å­")
    parser.add_argument("--epsilon", type=float, default=1.0, help="åˆå§‹æ¢ç´¢ç‡")
    parser.add_argument("--epsilon_min", type=float, default=0.01, help="æœ€å°æ¢ç´¢ç‡")
    parser.add_argument("--epsilon_decay", type=float, default=0.9995, help="æ¢ç´¢ç‡è¡°å‡å› å­")
    parser.add_argument("--memory_size", type=int, default=50000, help="ç»éªŒå›æ”¾ç¼“å†²åŒºå¤§å°")
    parser.add_argument("--target_update_freq", type=int, default=500, help="ç›®æ ‡ç½‘ç»œæ›´æ–°é¢‘ç‡")
    
    # ç¯å¢ƒå¥–åŠ±å‚æ•°
    parser.add_argument("--success_reward", type=float, default=20.0, help="æˆåŠŸæ”»å‡»å¥–åŠ±")
    parser.add_argument("--query_penalty", type=float, default=0.5, help="æŸ¥è¯¢æƒ©ç½š")
    parser.add_argument("--diversity_bonus", type=float, default=1.0, help="å¤šæ ·æ€§å¥–åŠ±")
    parser.add_argument("--efficiency_bonus", type=float, default=2.0, help="æ•ˆç‡å¥–åŠ±")
    parser.add_argument("--confidence_threshold", type=float, default=0.7, help="ç½®ä¿¡åº¦é˜ˆå€¼")
    
    args = parser.parse_args()
    
    # è®¾ç½®éšæœºç§å­
    import random
    import numpy as np
    random.seed(args.random_seed)
    np.random.seed(args.random_seed)
    
    # åˆ›å»ºæ¨¡å‹ç›®å½•å’Œæ—¥å¿—ç›®å½•
    os.makedirs(args.model_dir, exist_ok=True)
    os.makedirs(args.log_dir, exist_ok=True)
    
    # åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
    logger = HydraLogger(log_dir=args.log_dir, results_dir=args.model_dir)
    
    logger.logger.info("ğŸš€ å¼€å§‹è®­ç»ƒå¿«é€ŸRLæ”»å‡»æ™ºèƒ½ä½“ï¼ˆæ”¯æŒæ•°æ®åˆ†å‰²ï¼‰")
    logger.logger.info(f"Benchmark: {args.benchmark}")
    logger.logger.info(f"å®éªŒç›®å½•: {args.model_dir}")
    logger.logger.info(f"æ—¥å¿—ç›®å½•: {args.log_dir}")
    logger.logger.info(f"æ€»æ ·æœ¬æ•°: {args.max_samples}")
    logger.logger.info(f"æ•°æ®åˆ†å‰²: è®­ç»ƒ{args.train_ratio:.1%} / æµ‹è¯•{args.test_ratio:.1%} / éªŒè¯{args.validation_ratio:.1%}")
    logger.logger.info(f"è®­ç»ƒè½®æ•°: {args.episodes}")
    logger.logger.info(f"æœ€å¤§æŸ¥è¯¢æ¬¡æ•°: {args.max_queries}")
    
    # åŠ è½½è®­ç»ƒæ•°æ®ï¼ˆä¼˜å…ˆä½¿ç”¨é¢„åˆ†å‰²æ•°æ®ï¼‰
    train_examples, validation_examples = load_benchmark_data(args.benchmark, args.max_samples, args.random_seed, args.validation_ratio)
    if not train_examples:
        logger.logger.error("âŒ æ— æ³•åŠ è½½è®­ç»ƒæ•°æ®")
        return
    
    logger.logger.info(f"âœ… åŠ è½½äº† {len(train_examples)} ä¸ªè®­ç»ƒæ ·æœ¬")
    if validation_examples:
        logger.logger.info(f"âœ… åŠ è½½äº† {len(validation_examples)} ä¸ªéªŒè¯æ ·æœ¬")
    
    # åŠ è½½æµ‹è¯•æ•°æ®ï¼ˆå¿…é¡»ä½¿ç”¨é¢„åˆ†å‰²çš„æµ‹è¯•æ•°æ®ï¼‰
    test_file = f"data/split/{args.benchmark}_test.json"
    test_examples = []
    
    if not os.path.exists(test_file):
        logger.logger.error(f"âŒ é¢„åˆ†å‰²çš„æµ‹è¯•æ•°æ®ä¸å­˜åœ¨: {test_file}")
        logger.logger.error("è¯·å…ˆè¿è¡Œ prepare_data.py è„šæœ¬å‡†å¤‡æ•°æ®åˆ†å‰²")
        raise FileNotFoundError(f"é¢„åˆ†å‰²çš„æµ‹è¯•æ•°æ®ä¸å­˜åœ¨: {test_file}")
    
    # ä½¿ç”¨é¢„åˆ†å‰²çš„æµ‹è¯•æ•°æ®
    with open(test_file, 'r') as f:
        test_data = json.load(f)
    
    for sample in test_data:
        example = PairwiseExample(
            question_id=sample["question_id"],
            instruction=sample["instruction"],
            response_a=sample["response_a"],
            response_b=sample["response_b"],
            model_a=sample["model_a"],
            model_b=sample["model_b"],
            metadata=sample.get("metadata", {})
        )
        test_examples.append(example)
    
    logger.logger.info(f"âœ… ä½¿ç”¨é¢„åˆ†å‰²çš„æµ‹è¯•æ•°æ®: {len(test_examples)} ä¸ªæ ·æœ¬")
    
    # åˆ›å»ºæ”»å‡»æ–¹æ³•
    attacks = get_attack_methods()
    logger.logger.info(f"âœ… åŠ è½½äº† {len(attacks)} ç§æ”»å‡»æ–¹æ³•")
    
    # åˆ›å»ºJudge
    try:
        if args.judge_type == "qwen":
            judge = create_qwen_judge()
        elif args.judge_type == "llama":
            judge = create_llama_judge()
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„Judgeç±»å‹: {args.judge_type}")
        logger.logger.info("âœ… Judgeåˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        logger.logger.error(f"âŒ Judgeåˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # åˆ›å»ºè®­ç»ƒç¯å¢ƒ
    train_env = EnhancedHydraAttackEnv(
        examples=train_examples,
        attacks=attacks,
        judge=judge,
        max_queries=args.max_queries,
        success_reward=args.success_reward,
        query_penalty=args.query_penalty,
        diversity_bonus=args.diversity_bonus,
        efficiency_bonus=args.efficiency_bonus,
        confidence_threshold=args.confidence_threshold
    )
    
    # åˆ›å»ºDQNæ™ºèƒ½ä½“
    state_dim = train_env.observation_space.shape[0]
    action_dim = train_env.action_space.n
    
    agent = DQNAgent(
        state_dim=state_dim,
        action_dim=action_dim,
        hidden_dim=args.hidden_dim,
        learning_rate=args.learning_rate,
        gamma=args.gamma,
        epsilon=args.epsilon,
        epsilon_min=args.epsilon_min,
        epsilon_decay=args.epsilon_decay,
        batch_size=args.batch_size,
        memory_size=args.memory_size,
        target_update_freq=args.target_update_freq
    )
    
    logger.logger.info(f"âœ… åˆ›å»ºDQNæ™ºèƒ½ä½“: çŠ¶æ€ç»´åº¦={state_dim}, åŠ¨ä½œç»´åº¦={action_dim}")
    logger.logger.info(f"   DQNå‚æ•°: å­¦ä¹ ç‡={args.learning_rate}, æ‰¹æ¬¡å¤§å°={args.batch_size}, éšè—å±‚ç»´åº¦={args.hidden_dim}")
    logger.logger.info(f"   æ¢ç´¢å‚æ•°: Îµ={args.epsilon}, Îµ_min={args.epsilon_min}, Îµ_decay={args.epsilon_decay}")
    logger.logger.info(f"   ç½‘ç»œå‚æ•°: Î³={args.gamma}, å†…å­˜å¤§å°={args.memory_size}, ç›®æ ‡æ›´æ–°é¢‘ç‡={args.target_update_freq}")
    logger.logger.info(f"   ç¯å¢ƒå‚æ•°: æˆåŠŸå¥–åŠ±={args.success_reward}, æŸ¥è¯¢æƒ©ç½š={args.query_penalty}, ç½®ä¿¡åº¦é˜ˆå€¼={args.confidence_threshold}")
    
    # åˆ›å»ºæµ‹è¯•ç¯å¢ƒç”¨äºè®­ç»ƒè¿‡ç¨‹ä¸­çš„è¯„ä¼°
    test_env = EnhancedHydraAttackEnv(
        examples=test_examples,
        attacks=attacks,
        judge=judge,
        max_queries=args.max_queries,
        success_reward=args.success_reward,
        query_penalty=args.query_penalty,
        diversity_bonus=args.diversity_bonus,
        efficiency_bonus=args.efficiency_bonus,
        confidence_threshold=args.confidence_threshold
    )
    
    # åˆ›å»ºè®­ç»ƒå™¨
    config = RLConfig(
        algorithm="dqn",
        total_timesteps=args.episodes,
        learning_rate=args.learning_rate,
        batch_size=args.batch_size,
        gamma=args.gamma,
        epsilon_start=args.epsilon,
        epsilon_end=args.epsilon_min,
        epsilon_decay=args.epsilon_decay,
        target_update_freq=args.target_update_freq,
        save_freq=1000000,  # è®¾ç½®ä¸ºå¾ˆå¤§çš„å€¼ï¼Œå®é™…ä¸Šä¸ä¼šè§¦å‘ä¿å­˜
        eval_freq=args.eval_freq,
        max_queries=args.max_queries,
        success_reward=args.success_reward,
        query_penalty=args.query_penalty,
        diversity_bonus=args.diversity_bonus,
        efficiency_bonus=args.efficiency_bonus,
        confidence_threshold=args.confidence_threshold,
        early_stopping_patience=args.early_stopping_patience,
        early_stopping_min_delta=args.early_stopping_min_delta,
    )
    
    trainer = RLTrainer(
        env=train_env,
        agent=agent,
        config=config,
        save_dir=args.model_dir,
        test_env=test_env,  # ä¼ å…¥æµ‹è¯•ç¯å¢ƒç”¨äºè¯„ä¼°
        test_examples=test_examples,  # ä¼ å…¥æµ‹è¯•æ ·æœ¬ç”¨äºevaluate_on_unseen_data
        validation_examples=validation_examples,  # ä¼ å…¥éªŒè¯æ ·æœ¬ç”¨äºå‘¨æœŸæ€§éªŒè¯å’Œearly stopping
        attacks=attacks,  # ä¼ å…¥æ”»å‡»æ–¹æ³•
        judge=judge,  # ä¼ å…¥judge
        logger=logger  # ä¼ å…¥logger
    )
    
    # å¼€å§‹è®­ç»ƒ
    logger.logger.info("ğŸ¯ å¼€å§‹è®­ç»ƒ...")
    start_time = time.time()
    
    training_results = trainer.train(args.episodes)
    
    training_time = time.time() - start_time
    logger.logger.info(f"ğŸ‰ è®­ç»ƒå®Œæˆï¼")
    logger.logger.info(f"â±ï¸  è®­ç»ƒè€—æ—¶: {training_time:.2f}ç§’")
    
    # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°ï¼ˆçœŸæ­£çš„æœªè§æ•°æ®ï¼‰
    logger.logger.info("ğŸ” åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹ï¼ˆæœªè§æ•°æ®ï¼‰...")
    test_results = evaluate_on_unseen_data(agent, test_examples, attacks, judge, args.max_queries, 
                                         args.success_reward, args.query_penalty, args.diversity_bonus, 
                                         args.efficiency_bonus, args.confidence_threshold, logger)
    
    # ä¿å­˜æ¨¡å‹ - æ–‡ä»¶ååŒ…å«æ•°æ®é›†ä¿¡æ¯ï¼Œæ–°æ¨¡å‹ä¼šè¦†ç›–æ—§æ¨¡å‹
    model_path = os.path.join(args.model_dir, f"fast_rl_attacker_{args.benchmark}.pth")
    agent.save_model(model_path)
    logger.logger.info(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
    
    # ä¿å­˜åŠ¨ä½œæ˜ å°„ - æ–‡ä»¶ååŒ…å«æ•°æ®é›†ä¿¡æ¯ï¼Œæ–°æ¨¡å‹ä¼šè¦†ç›–æ—§æ¨¡å‹
    action_mapping = {}
    for i, attack in enumerate(attacks):
        for j in range(attack.get_action_space_size()):
            action_mapping[i * 100 + j] = {
                'attack_method': attack.__class__.__name__,
                'action_id': j,
                'action_description': attack.get_action_description(j)
            }
    
    mapping_path = os.path.join(args.model_dir, f"action_mapping_{args.benchmark}.json")
    with open(mapping_path, 'w') as f:
        json.dump(action_mapping, f, indent=2)
    logger.logger.info(f"ğŸ’¾ åŠ¨ä½œæ˜ å°„å·²ä¿å­˜åˆ°: {mapping_path}")
    
    # ä¿å­˜è®­ç»ƒé…ç½®å’Œç»“æœ - æ–‡ä»¶ååŒ…å«æ•°æ®é›†ä¿¡æ¯ï¼Œæ–°æ¨¡å‹ä¼šè¦†ç›–æ—§æ¨¡å‹
    config_dict = {
        'algorithm': 'DQN',
        'benchmark': args.benchmark,
        'max_samples': args.max_samples,
        'train_ratio': args.train_ratio,
        'test_ratio': args.test_ratio,
        'episodes': args.episodes,
        'max_queries': args.max_queries,
        'learning_rate': args.learning_rate,
        'batch_size': args.batch_size,
        'random_seed': args.random_seed,
        'training_time': training_time,
        'train_samples': len(train_examples),
        'test_samples': len(test_examples),
        'validation_samples': len(validation_examples),
        'test_results': test_results,
        'dqn_params': {
            'hidden_dim': args.hidden_dim,
            'gamma': args.gamma,
            'epsilon': args.epsilon,
            'epsilon_min': args.epsilon_min,
            'epsilon_decay': args.epsilon_decay,
            'memory_size': args.memory_size,
            'target_update_freq': args.target_update_freq
        },
        'env_params': {
            'success_reward': args.success_reward,
            'query_penalty': args.query_penalty,
            'diversity_bonus': args.diversity_bonus,
            'efficiency_bonus': args.efficiency_bonus,
            'confidence_threshold': args.confidence_threshold
        },
        'early_stopping_params': {
            'patience': args.early_stopping_patience,
            'min_delta': args.early_stopping_min_delta
        }
    }
    
    config_path = os.path.join(args.model_dir, f"training_config_{args.benchmark}.json")
    # è½¬æ¢numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹
    config_dict = convert_numpy_types(config_dict)
    with open(config_path, 'w') as f:
        json.dump(config_dict, f, indent=2)
    logger.logger.info(f"ğŸ’¾ è®­ç»ƒé…ç½®å·²ä¿å­˜åˆ°: {config_path}")
    
    # è¾“å‡ºæœ€ç»ˆç»“æœ
    logger.logger.info("=" * 80)
    logger.logger.info("ğŸ“Š æœ€ç»ˆè®­ç»ƒç»“æœ")
    logger.logger.info("=" * 80)
    logger.logger.info(f"è®­ç»ƒé›†è¡¨ç°: {training_results['final_eval']}")
    logger.logger.info(f"æµ‹è¯•é›†è¡¨ç°ï¼ˆæœªè§æ•°æ®ï¼‰: {test_results}")
    logger.logger.info("=" * 80)
    
    return {
        'training_results': training_results,
        'test_results': test_results,
        'config': config_dict
    }


if __name__ == "__main__":
    main()
